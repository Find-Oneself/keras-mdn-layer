{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Input, merge\n",
    "from keras.engine.topology import Layer\n",
    "import numpy as np\n",
    "from tensorflow.contrib.distributions import Categorical, Mixture, MultivariateNormalDiag\n",
    "import tensorflow as tf\n",
    "\n",
    "class MDN(Layer):\n",
    "    \"\"\"A Mixture Density Network Layer for Keras.\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dim, num_mix, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.num_mix = num_mix\n",
    "        with tf.name_scope('MDN'):\n",
    "            self.mdn_mus     = Dense(self.num_mix * self.output_dim, name='mdn_mus') # mix*output vals, no activation\n",
    "            self.mdn_sigmas  = Dense(self.num_mix * self.output_dim, activation=K.exp, name='mdn_sigmas') # mix*output vals exp activation\n",
    "            self.mdn_pi      = Dense(self.num_mix, activation=K.softmax, name='mdn_pi') # mix vals, softmax\n",
    "        super(MDN, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.mdn_mus.build(input_shape)\n",
    "        self.mdn_sigmas.build(input_shape)\n",
    "        self.mdn_pi.build(input_shape)\n",
    "        self.trainable_weights = self.mdn_mus.trainable_weights + self.mdn_sigmas.trainable_weights + self.mdn_pi.trainable_weights\n",
    "        self.non_trainable_weights = self.mdn_mus.non_trainable_weights + self.mdn_sigmas.non_trainable_weights + self.mdn_pi.non_trainable_weights\n",
    "        super(MDN, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x, mask=None):\n",
    "        with tf.name_scope('MDN'):\n",
    "            mdn_out = keras.layers.concatenate([self.mdn_mus(x), \n",
    "                                                self.mdn_sigmas(x), \n",
    "                                                self.mdn_pi(x)], \n",
    "                                               name='mdn_outputs')\n",
    "        return mdn_out\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "\n",
    "\n",
    "def get_mixture_loss_func(output_dim, num_mixes):\n",
    "    \"\"\"Construct a loss functions for the MDN layer parametrised by number of mixtures.\"\"\"\n",
    "    \n",
    "    # Construct a loss function with the right number of mixtures and outputs\n",
    "    def loss_func(y_true, y_pred):\n",
    "        out_mu, out_sigma, out_pi = tf.split(y_pred, num_or_size_splits=[num_mixes * output_dim, \n",
    "                                                                         num_mixes * output_dim, \n",
    "                                                                         num_mixes], \n",
    "                                             axis=1, name='mdn_coef_split')\n",
    "        cat = Categorical(logits=out_pi)\n",
    "        component_splits = [output_dim] * num_mixes\n",
    "        mus = tf.split(out_mu, num_or_size_splits=component_splits, axis=1)\n",
    "        sigs = tf.split(out_sigma, num_or_size_splits=component_splits, axis=1)\n",
    "        coll = [MultivariateNormalDiag(loc=loc, scale_diag=scale) for loc, scale\n",
    "            in zip(mus, sigs)]\n",
    "        mixture = Mixture(cat=cat, components=coll)\n",
    "        loss = mixture.log_prob(y_true)\n",
    "        loss = tf.negative(loss)\n",
    "        return loss\n",
    "    \n",
    "    # Actually return the loss_func\n",
    "    with tf.name_scope('MDN'):\n",
    "        return loss_func\n",
    "    \n",
    "def get_mixture_sampling_fun(output_dim, num_mixes):\n",
    "    \"\"\"Construct a sampling function for the MDN layer parametrised by mixtures and output dimension.\"\"\"\n",
    "        \n",
    "    # Construct a loss function with the right number of mixtures and outputs\n",
    "    def sampling_func(y_pred):\n",
    "        out_mu, out_sigma, out_pi = tf.split(y_pred, num_or_size_splits=[num_mixes * output_dim, \n",
    "                                                                         num_mixes * output_dim, \n",
    "                                                                         num_mixes], \n",
    "                                             axis=1, name='mdn_coef_split')\n",
    "        cat = Categorical(logits=out_pi)\n",
    "        component_splits = [output_dim] * num_mixes\n",
    "        mus = tf.split(out_mu, num_or_size_splits=component_splits, axis=1)\n",
    "        sigs = tf.split(out_sigma, num_or_size_splits=component_splits, axis=1)\n",
    "        coll = [MultivariateNormalDiag(loc=loc, scale_diag=scale) for loc, scale\n",
    "            in zip(mus, sigs)]\n",
    "        mixture = Mixture(cat=cat, components=coll)\n",
    "        samp = mixture.sample()\n",
    "        # Todo: temperature adjustment for sampling function.\n",
    "        return samp\n",
    "    \n",
    "    # Actually return the loss_func\n",
    "    with tf.name_scope('MDNLayer'):\n",
    "        return sampling_func\n",
    "    \n",
    "def get_mixture_mse_accuracy(output_dim, num_mixes):\n",
    "    \"\"\"Construct an MSE accuracy function for the MDN layer \n",
    "    that takes one sample and compares to the true value.\"\"\"\n",
    "    \n",
    "    # Construct a loss function with the right number of mixtures and outputs\n",
    "    def mse_func(y_true, y_pred):\n",
    "        out_mu, out_sigma, out_pi = tf.split(y_pred, num_or_size_splits=[num_mixes * output_dim, \n",
    "                                                                         num_mixes * output_dim, \n",
    "                                                                         num_mixes], \n",
    "                                             axis=1, name='mdn_coef_split')\n",
    "        cat = Categorical(logits=out_pi)\n",
    "        component_splits = [output_dim] * num_mixes\n",
    "        mus = tf.split(out_mu, num_or_size_splits=component_splits, axis=1)\n",
    "        sigs = tf.split(out_sigma, num_or_size_splits=component_splits, axis=1)\n",
    "        coll = [MultivariateNormalDiag(loc=loc, scale_diag=scale) for loc, scale\n",
    "            in zip(mus, sigs)]\n",
    "        mixture = Mixture(cat=cat, components=coll)\n",
    "        samp = mixture.sample()\n",
    "        mse = tf.reduce_mean(tf.square(samp - y_true), axis=-1)\n",
    "        # Todo: temperature adjustment for sampling functon.\n",
    "        return mse\n",
    "    \n",
    "    # Actually return the loss_func\n",
    "    with tf.name_scope('MDNLayer'):\n",
    "        return mse_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 64)                17408     \n",
      "_________________________________________________________________\n",
      "mdn_6 (MDN)                  (None, 3)                 2275      \n",
      "=================================================================\n",
      "Total params: 19,683\n",
      "Trainable params: 19,683\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIMENSION = 3\n",
    "NUMBER_MIXTURES = 5\n",
    "SEQ_LEN = 10\n",
    "HIDDEN_UNITS = 64\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(HIDDEN_UNITS, batch_input_shape=(None,SEQ_LEN,OUTPUT_DIMENSION)))\n",
    "model.add(MDN(OUTPUT_DIMENSION, NUMBER_MIXTURES))\n",
    "model.compile(loss=get_mixture_loss_func(OUTPUT_DIMENSION,NUMBER_MIXTURES), optimizer=keras.optimizers.Adam(), metrics=[get_mixture_mse_accuracy(3,5)])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
